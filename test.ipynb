{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:45<00:00, 215805.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 118518.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:09<00:00, 173388.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 6446879.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "\n",
    "# Load MNIST dataset\n",
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1000, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainset size: 60000\n",
      "Testset size: 10000\n",
      "torch.Size([1, 28, 28])\n",
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "print('Trainset size:', len(trainset))\n",
    "print('Testset size:', len(testset))\n",
    "print(trainset[0][0].shape)\n",
    "print(testset[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OriginalModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OriginalModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc1 = nn.Linear(32 * 14 * 14, 128)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.bn1(self.conv1(x)))\n",
    "        x = self.relu2(self.bn2(self.conv2(x)))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FusedModel(nn.Module):\n",
    "    def __init__(self, original_model):\n",
    "        super(FusedModel, self).__init__()\n",
    "        self.conv1 = self.fuse_conv_bn(original_model.conv1, original_model.bn1)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.conv2 = self.fuse_conv_bn(original_model.conv2, original_model.bn2)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc1 = original_model.fc1\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.fc2 = original_model.fc2\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.conv1(x))\n",
    "        x = self.relu2(self.conv2(x))\n",
    "        x = nn.functional.max_pool2d(x, 2)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.relu3(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "    def fuse_conv_bn(self, conv, bn):\n",
    "        with torch.no_grad():\n",
    "            # Initialize a new convolutional layer with the same parameters\n",
    "            fused_conv = nn.Conv2d(conv.in_channels,\n",
    "                                   conv.out_channels,\n",
    "                                   kernel_size=conv.kernel_size,\n",
    "                                   stride=conv.stride,\n",
    "                                   padding=conv.padding,\n",
    "                                   bias=True)\n",
    "            \n",
    "            # Extract the batch normalization parameters\n",
    "            gamma = bn.weight\n",
    "            beta = bn.bias\n",
    "            mean = bn.running_mean\n",
    "            var = bn.running_var\n",
    "            eps = bn.eps\n",
    "\n",
    "            # Extract the convolutional parameters\n",
    "            W = conv.weight\n",
    "            if conv.bias is None:\n",
    "                b = torch.zeros_like(mean)\n",
    "            else:\n",
    "                b = conv.bias\n",
    "            \n",
    "            print(f\"Conv weight shape: {W.shape}\")\n",
    "            print(f\"BN gamma shape: {gamma.shape}\")\n",
    "            print(f\"BN beta shape: {beta.shape}\")\n",
    "            print(f\"BN mean shape: {mean.shape}\")\n",
    "            print(f\"BN var shape: {var.shape}\")\n",
    "\n",
    "            # Reshape the batch normalization parameters for broadcasting\n",
    "            gamma = gamma.view(-1, 1, 1, 1)\n",
    "            beta = beta.view(-1)\n",
    "            mean = mean.view(-1, 1, 1, 1)\n",
    "            var = var.view(-1, 1, 1, 1)\n",
    "\n",
    "            # Fuse the weights and biases\n",
    "            W_fused = W * (gamma / torch.sqrt(var + eps))\n",
    "            b_fused = beta + (b - mean.squeeze()) * (gamma.squeeze() / torch.sqrt(var.squeeze() + eps))\n",
    "\n",
    "            # Copy the fused parameters to the new convolutional layer\n",
    "            fused_conv.weight.copy_(W_fused)\n",
    "            fused_conv.bias.copy_(b_fused)\n",
    "            print(f\"Fused weight shape: {fused_conv.weight.shape}\")\n",
    "            print(f\"Fused bias shape: {fused_conv.bias.shape}\")\n",
    "        \n",
    "        return fused_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv weight shape: torch.Size([16, 1, 3, 3])\n",
      "BN gamma shape: torch.Size([16])\n",
      "BN beta shape: torch.Size([16])\n",
      "BN mean shape: torch.Size([16])\n",
      "BN var shape: torch.Size([16])\n",
      "Fused weight shape: torch.Size([16, 1, 3, 3])\n",
      "Fused bias shape: torch.Size([16])\n",
      "Conv weight shape: torch.Size([32, 16, 3, 3])\n",
      "BN gamma shape: torch.Size([32])\n",
      "BN beta shape: torch.Size([32])\n",
      "BN mean shape: torch.Size([32])\n",
      "BN var shape: torch.Size([32])\n",
      "Fused weight shape: torch.Size([32, 16, 3, 3])\n",
      "Fused bias shape: torch.Size([32])\n",
      "Training original model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Loss: 0.1508\n",
      "Epoch 2/5, Loss: 0.0489\n",
      "Epoch 3/5, Loss: 0.0329\n",
      "Epoch 4/5, Loss: 0.0254\n",
      "Epoch 5/5, Loss: 0.0206\n",
      "Training fused model...\n",
      "Epoch 1/5, Loss: 0.0738\n",
      "Epoch 2/5, Loss: 0.0226\n",
      "Epoch 3/5, Loss: 0.0145\n",
      "Epoch 4/5, Loss: 0.0114\n",
      "Epoch 5/5, Loss: 0.0088\n",
      "Original model accuracy: 98.66%\n",
      "Fused model accuracy: 98.98%\n",
      "Original model inference time: 0.000458 seconds\n",
      "Fused model inference time: 0.000372 seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Training and evaluation functions\n",
    "def train(model, trainloader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    return running_loss / len(trainloader)\n",
    "\n",
    "def evaluate(model, testloader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "# Measure inference time\n",
    "def measure_inference_time(model, input_tensor, iterations=100):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        start_time = time.time()\n",
    "        for _ in range(iterations):\n",
    "            _ = model(input_tensor)\n",
    "        end_time = time.time()\n",
    "    return (end_time - start_time) / iterations\n",
    "\n",
    "# Main script\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate models\n",
    "original_model = OriginalModel().to(device)\n",
    "fused_model = FusedModel(original_model).to(device)\n",
    "\n",
    "# Loss function and optimizers\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer_original = optim.Adam(original_model.parameters(), lr=0.001)\n",
    "optimizer_fused = optim.Adam(fused_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5\n",
    "\n",
    "print(\"Training original model...\")\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(original_model, trainloader, criterion, optimizer_original, device)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}\")\n",
    "\n",
    "print(\"Training fused model...\")\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = train(fused_model, trainloader, criterion, optimizer_fused, device)\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}, Loss: {train_loss:.4f}\")\n",
    "\n",
    "# Evaluate models\n",
    "original_accuracy = evaluate(original_model, testloader, device)\n",
    "fused_accuracy = evaluate(fused_model, testloader, device)\n",
    "print(f\"Original model accuracy: {original_accuracy:.2f}%\")\n",
    "print(f\"Fused model accuracy: {fused_accuracy:.2f}%\")\n",
    "\n",
    "# Generate random input for inference time measurement\n",
    "input_tensor = torch.randn(1, 1, 28, 28).to(device)\n",
    "\n",
    "# Measure inference time for original model\n",
    "original_time = measure_inference_time(original_model, input_tensor)\n",
    "print(f\"Original model inference time: {original_time:.6f} seconds\")\n",
    "\n",
    "# Measure inference time for fused model\n",
    "fused_time = measure_inference_time(fused_model, input_tensor)\n",
    "print(f\"Fused model inference time: {fused_time:.6f} seconds\")\n",
    "\n",
    "# Verify outputs are the same on a batch\n",
    "input_tensor, _ = next(iter(testloader))\n",
    "input_tensor = input_tensor.to(device)\n",
    "original_output = original_model(input_tensor)\n",
    "fused_output = fused_model(input_tensor)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
